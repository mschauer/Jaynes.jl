<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Concepts · Jaynes.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="Jaynes.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">Jaynes.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Introduction</a></li><li><a class="tocitem" href="../modeling_lang/">Modeling language</a></li><li><a class="tocitem" href="../examples/">Examples</a></li><li class="is-active"><a class="tocitem" href>Concepts</a><ul class="internal"><li><a class="tocitem" href="#Universal-probabilistic-programming"><span>Universal probabilistic programming</span></a></li><li><a class="tocitem" href="#The-choice-map-abstraction"><span>The choice map abstraction</span></a></li><li><a class="tocitem" href="#Choice-and-call-site-abstractions"><span>Choice and call site abstractions</span></a></li><li><a class="tocitem" href="#Implementing-a-context"><span>Implementing a context</span></a></li></ul></li><li><a class="tocitem" href="../architecture/">Architecture</a></li><li><span class="tocitem">Library</span><ul><li><a class="tocitem" href="../library_api/sites/">Traces, choices, and call sites</a></li><li><a class="tocitem" href="../library_api/contexts/">Execution contexts</a></li><li><a class="tocitem" href="../library_api/selection_interface/">Selection interface</a></li><li><input class="collapse-toggle" id="menuitem-6-4" type="checkbox"/><label class="tocitem" for="menuitem-6-4"><span class="docs-label">Inference</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../inference/is/">Importance sampling</a></li><li><a class="tocitem" href="../inference/mh/">Metropolis-Hastings</a></li><li><a class="tocitem" href="../inference/pf/">Particle filtering</a></li><li><a class="tocitem" href="../inference/vi/">Automatic differentiation variational inference</a></li></ul></li><li><a class="tocitem" href="../library_api/fmi/">Foreign model interface</a></li><li><a class="tocitem" href="../library_api/diff_prog/">Differentiable programming</a></li></ul></li><li><a class="tocitem" href="../benchmarks/">Benchmarks</a></li><li><a class="tocitem" href="../related_work/">Related work</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Concepts</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Concepts</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/femtomc/Jaynes.jl/blob/master/docs/src/concepts.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><p>The majority of the concepts used in the initial implementation of this package come from a combination of research papers and research systems (the most notable in the Julia ecosystem is <a href="https://www.gen.dev/">Gen</a>). See <a href="../related_work/">Related Work</a> for a more comprehensive list of references.</p><h2 id="Universal-probabilistic-programming"><a class="docs-heading-anchor" href="#Universal-probabilistic-programming">Universal probabilistic programming</a><a id="Universal-probabilistic-programming-1"></a><a class="docs-heading-anchor-permalink" href="#Universal-probabilistic-programming" title="Permalink"></a></h2><p>Probabilistic programming systems are classified according to their ability to express the subset of stochastic computable functions which form valid probability distributions over program execution (in some interpretation). That&#39;s a terrible mouthful - but it&#39;s wide enough to conveniently capture systems which focus on Bayesian networks, as well as systems which capture a wider set of programs, which we will examine shortly. </p><p>Probabilistic programming systems which restrict allowable forms of control flow or recursion are referred to as <em>first-order</em> probabilistic programming systems. The support of the distribution over samples sites which a <em>first-order</em> program defines can be known at compile time - this implies that these programs can be translated safely to a static graph representation (a Bayesian network). This representation can also be attained if control flow can be <em>unrolled</em> using compiler techniques like <em>constant propagation</em>.</p><p>A static graph representation constructed at compile time is useful, but it&#39;s not sufficient to express all valid densities over program execution. <em>Higher-order</em> or <em>universal</em> probabilistic programming frameworks include the ability to handle stochasticity in control flow bounds and recursion. In general, these frameworks include the ability to handle runtime sources of randomness which can&#39;t be identified at compile time. To achieve this generality, frameworks which support the ability to express these sorts of probabilistic programs are typically restricted to sampling-based inference methods. Here, we first get a glimpse of the (well-known) duality between a <em>compiler-based approach</em> to model representation and <em>interpreter-based approaches</em> which allow for random computation to be determined at runtime). Modern systems blur the line between these approaches (see <a href="https://www.gen.dev/dev/ref/modeling/#Static-Modeling-Language-1">Gen&#39;s static DSL</a> for example) when analysis or annotation can improve inference performance.</p><h2 id="The-choice-map-abstraction"><a class="docs-heading-anchor" href="#The-choice-map-abstraction">The choice map abstraction</a><a id="The-choice-map-abstraction-1"></a><a class="docs-heading-anchor-permalink" href="#The-choice-map-abstraction" title="Permalink"></a></h2><p>One important concept in the universal space is the notion of a mapping from call sites where random choices occur to the values at those sites. This map is called a <em>choice map</em> in most implementations (original representation in <a href="http://proceedings.mlr.press/v15/wingate11a/wingate11a.pdf">Bher</a>). The semantic interpretation of a probabilistic program expressed in a framework which supports universal probabilistic programming via the choice map abstraction is a distribution over choice maps. Consider the following program, which expresses the geometric distribution in this framework:</p><pre><code class="language-julia">geo(p::Float64) = rand(:flip, Bernoulli, (p, )) == 1 ? 0 : 1 + rand(:geo, geo, p)</code></pre><p>Here, <code>rand</code> call sites are also given addresses and recursive calls produce a hierarchical address space. A sample from the distribution over choice maps for this program might produce the following map:</p><pre><code class="language-julia"> :geo =&gt; :flip : false
 flip : false
 :geo =&gt; (:geo =&gt; :flip) : false
 :geo =&gt; (:geo =&gt; (:geo =&gt; :flip)) : false
 :geo =&gt; (:geo =&gt; (:geo =&gt; (:geo =&gt; :flip))) : true</code></pre><p>One simple question arises: what exactly does this <em>distribution over choice maps</em> look like in a mathematical sense? To answer this question, we have to ask how control flow and iteration language features affect the &quot;abstract space&quot; of the shape of the program trace. For the moment, we will consider only randomness which occurs explicitly at addresses in each method call (i.e. <code>rand</code> calls with distributions as target) - it turns out that we can safely focus on the shape of the trace in this case without loss of generalization. Randomness which occurs inside of a <code>rand</code> call where the target of the call is another method call can be handled by the same techniques we introduce to analyze the shape of a single method body without target calls.</p><h2 id="Choice-and-call-site-abstractions"><a class="docs-heading-anchor" href="#Choice-and-call-site-abstractions">Choice and call site abstractions</a><a id="Choice-and-call-site-abstractions-1"></a><a class="docs-heading-anchor-permalink" href="#Choice-and-call-site-abstractions" title="Permalink"></a></h2><p>Ideally, we&#39;d like the construction of probabilistic programs to parallel the construction of regular programs - we&#39;d like the additional probabilistic semantics to leave the original execution semantics invariant (mostly). In other words, we don&#39;t want to give up the powerful abstractions and features which we have become accustomed to while programming in Julia normally. Well, there&#39;s good news - you don&#39;t have to! You will have to keep a few new things in mind (see <a href="../modeling_lang/">the modeling language section</a> for more details) but the whole language should remain open for your use.</p><p>One of the ways which Jaynes accomplishes this is by creating a set of &quot;record site&quot; abstractions which denote places where the tracer can intercept and take over for the normal execution or call semantics which the programmer expects. This notion of an interception site is central to a number of compiler plug-in style systems (<a href="https://github.com/FluxML/IRTools.jl">IRTools</a> and <a href="https://github.com/jrevels/Cassette.jl">Cassette</a> included). Systems like these might see a call and intercept the call, possible replacing the call with another call with extra points of overloadability. Oh, I should also mention that these systems do this recursively through the call stack 😺. As far as I know, it is rare to be able to do this natively in languages. You definitely need your language to be dynamic and likely JIT compiled (so that you can access parts of the intermediate representation) - in other words, Julia.</p><p>To facilitate probabilistic programming, Jaynes intercepts calls to <code>rand</code> (as you might have guessed) and interprets them differently depending on the <em>execution context</em> which the user calls on their toplevel function. The normal Julia execution context is activated by simply calling the toplevel function directly - but Jaynes provides access to a number of additional contexts which perform useful functionality for the design and implementation of sample-based inference algorithms. In general:</p><ol><li><p>When Jaynes sees an addressed rand site <code>rand(:x, d)</code> where <code>d</code> is a <code>Distribution</code> instance from the <code>Distributions</code> package, it intercepts it and reasons about it as a <code>ChoiceSite</code> record of the interception, which may include recording some metadata to facilitate inference, or performing other operations.</p></li><li><p>When Jaynes sees an addressed rand site <code>rand(:x, fn, args...)</code>, it intercepts it and reasons about it as a <code>CallSite</code> record of the interception, which may include recording some metadata to facilitate inference, before then recursing into the call to find other points of interception.</p></li></ol><p>These are the two basic patterns which are repeated throughout the implementation of execution contexts, which we will see in a moment.</p><h2 id="Implementing-a-context"><a class="docs-heading-anchor" href="#Implementing-a-context">Implementing a context</a><a id="Implementing-a-context-1"></a><a class="docs-heading-anchor-permalink" href="#Implementing-a-context" title="Permalink"></a></h2><p>In this section, we&#39;ll walk through the implementation of the <code>GenerateContext</code> execution context in full. This should give users of the library a good baseline understanding about how these execution contexts are implemented, and how they do what they do.</p><p>First, each context is a <em>dynamo</em> - which is safe <code>IRTools</code> version of Julia&#39;s <a href="https://docs.julialang.org/en/v1/manual/metaprogramming/#Generated-functions-1">generated functions</a>. Generated functions have access to type information and, thus, method bodies at compile time. Generated functions are typically used to push computation to compile time, but <a href="https://github.com/femtomc/Mixtape.jl/blob/937068b7fd1ead7dbbc9837903cf52d0ab3a48c8/src/Mixtape.jl#L42-L57">you can do wild things with them</a>. This link showcases a generated function and IR pass which recursively wraps function calls in itself, allow you to use dispatch to intercept function calls and do whatever you want with them at any level of the call stack. This fundamental idea is how libraries like <code>Cassette</code> and the dynamos of <code>IRTools</code> do what they do - this is compiler metaprogramming at its finest (although it is currently hard on the compiler).</p><p>Dynamos are essentially better behaved generated functions. If you look at that version of <code>Mixtape</code> - it took quite a number of tries to prevent the execution engine from segfaulting out. This never happens with dynamos. There are also a number of convenient benefits to working with <code>IRTools</code> - the SSA IR format provided by the library is very nice to work with, and there are a number of utilities for compiler enthusiasts to use when writing custom IR passes. For our implementation, we don&#39;t need of these advanced utilities - we will start with a simple dynamo:</p><pre><code class="language-julia">abstract type ExecutionContext end

@dynamo function (mx::ExecutionContext)(a...)
    ir = IR(a...)
    ir == nothing &amp;&amp; return
    recur!(ir)
    return ir
end</code></pre><p>This defines a <em>closure</em> - a callable object - as a dynamo (which, remember, is basically an easy-to-work-with generated function). What does this dynamo do? First, it grabs lowered metadata for a particular call, then it converts this metadata to <code>IRTools</code> IR with the call to <code>IR(a...)</code>. If the dynamo can&#39;t perform this first part of the process, the <code>IR</code> will safely be an instance of <code>Nothing</code>, so the dynamo will return <code>nothing</code>, which means that it just calls the original call with args. If you can derive IR for the call, you pass the IR into <code>recur!</code> which performs the sort of recursive wrapping from <code>Mixtape</code> in a safe way, so that the dynamo wraps every call down the stack (<code>recur!</code> is a <code>Jaynes</code> specific version of <code>recurse!</code> from <code>IRTools</code> which includes a few optimizations specific to <code>Jaynes</code>).</p><p>The end result of this definition is: if you define any concrete struct which inherits from <code>ExecutionContext</code>, you can call it on a function type and args, and it will wrap itself around every call in the resultant call stack - which means that, as the function call executes, any call on the branch you are on gets wrapped as well, and the transformation repeats itself, until it hits primitives for which it can&#39;t derived lowered metadata (and it will just call those primitives, instead of wrapping).</p><p>What does this afford us? Well, we can now define through dispatch the behavior for any function call we want, for any inheritor of <code>ExecutionContext</code>:</p><pre><code class="language-julia">mutable struct GenerateContext{T &lt;: Trace, K &lt;: ConstrainedSelection, P &lt;: Parameters} &lt;: ExecutionContext
    tr::T
    select::K
    weight::Float64
    score::Float64
    visited::Visitor
    params::P
end

@inline function (ctx::GenerateContext)(call::typeof(rand), 
                                        addr::T, 
                                        d::Distribution{K}) where {T &lt;: Address, K}
    visit!(ctx, addr)
    if has_query(ctx.select, addr)
        s = get_query(ctx.select, addr)
        score = logpdf(d, s)
        add_choice!(ctx, addr, ChoiceSite(score, s))
        increment!(ctx, score)
    else
        s = rand(d)
        add_choice!(ctx, addr, ChoiceSite(logpdf(d, s), s))
    end
    return s
end</code></pre><p>Now, we define a concrete inheritor of <code>ExecutionContext</code> called <code>GenerateContext</code> which keeps a few pieces of metadata around which we will use to record information about calls which include random choices. The inlined closure definition below the struct definition outlines what happens when the dynamo wrapping encounters a call of the following form:</p><pre><code class="language-julia">rand(addr::T, d::Distribution{K}) where T &lt;: Address</code></pre><p>where <code>Address</code> is a <code>Union{Symbol, Pair{Symbol, Int}}</code> and is used by the user to denote the sites in their probabilistic program which the tracer will pay attention to. What happens in this call instead of the normal execution for <code>rand(addr, d)</code>? First we do some bookkeeping to make sure the probabilistic program is valid using <code>visit!</code>, then we check a field called <code>select</code> to determine if the user has provided any constraints (i.e. observations) which the execution context should use to constrain this call at this address. If we do have a constraint, we grab the constraint, score it using <code>logpdf</code> for the distribution in the call and add a record of the call to a piece of metadata called a <code>Trace</code> in the execution context. Otherwise, we randomly sample and record the call in the <code>Trace</code>. Finally, we return the sample (or observation) <code>s</code>.</p><p>This is exactly what happens in the <code>GenerateContext</code> every time the dynamo sees a call of the <code>rand</code> form above instead of the normal execution. But this is exactly what we need to allow sampling of probabilistic programs where some of the address have user-provided constraints. And it all happens automatically, courtesy of compiler metaprogramming.</p><p>The other execution contexts are implemented in the same way - you&#39;ll also notice that this implementation is repeated in the set of <em>specialized call sites</em> which the user can activate if they&#39;d like to express part of a probabilistic program which confirms to a certain structure of randomness dependency. As long as the required interception occurs at the function call level, this compiler metaprogramming technique can be used. Very powerful!</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../examples/">« Examples</a><a class="docs-footer-nextpage" href="../architecture/">Architecture »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Sunday 19 July 2020 23:12">Sunday 19 July 2020</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
